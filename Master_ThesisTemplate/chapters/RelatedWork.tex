\chapter{Related Work}

There are many annotation languages proposed until now for
extending the C type system \cite{ref_54_condit:dependent}, \cite{ref_53_evans:static,ref_51_microsoft:sal,ref_55_sun:lock,ref_56_torvalds:sparse} to be
used during run-time as a new language run-time for PHP and
Python \cite{ref_57_alex:improving} to annotate function interfaces \cite{ref_53_evans:static,ref_51_microsoft:sal,ref_56_torvalds:sparse} to
annotate models in order to detect information flow bugs \cite{ref_58_iflow:kuzman}
to annotate source code files \cite{ref_59_rosenblum:towards,ref_60_rosenblum:practical,ref_61_lintan:acomment} or to annotate
control flows \cite{ref_53_evans:static,ref_52_splint:flow,ref_51_microsoft:sal}. The following annotation languages have made significant impact: Microsoft\'s SAL annotations \cite{ref_51_microsoft:sal} helped to detect more than 1000 potential security vulnerabilities in Windows
code \cite{ref_50_ball:research}. In addition, several other annotation languages including  Jif \cite{ref_48_chong:jif}, AURA \cite{ref_46_jia:aura}, FlowCaml \cite{ref_32_simonet:report}, FINE \cite{ref_45_nikhil:fine} and Fable \cite{ref_47_swamy:fable} express information flow related concerns.

Saner \cite{ref_61_lintan:acomment}, a novel approach to the evaluation of the sanitization process in web applications. The approach relies on two complementary analysis techniques to identify faulty sanitization procedures. Saner \cite{ref_61_lintan:acomment} introduce a dynamic analysis technique that is
able to reconstruct the code that is responsible for
the sanitization of application inputs, and then execute this code on malicious inputs to identify faulty
sanitization procedures. By applying
it to real-world applications, identified novel vulnerabilities that stem from incorrect or incomplete sanitization.

A simple idea named trusted declassification \cite{ref_2_hicks2006trusted} in which special declassifier functions are specified as part of the global policy. In particular, individual principals declaratively specify which declassifiers they trust so that all information flows implied by the policy can be reasoned about in absence of a particular program. They formalize their approach for a Java like language and prove a modified form of noninterference which they call noninterference modulo trusted methods. They have implemented their approach as an extension to Jif and provide some of their experience using it to build a secure e-mail client.

Using RESIN \cite{ref_63_yip2009improving}, Web application programmers can prevent a range
of problems, from SQL injection and cross-site scripting, to inadvertent password disclosure and missing access control checks. Adding
a RESIN assertion to an application requires few changes to the
existing application code, and an assertion can reuse existing code
and data structures. For instance, 23 lines of code detect and prevent
three previously-unknown missing access control vulnerabilities in
phpBB, a popular Web forum application. Other assertions comprising tens of lines of code prevent a range of vulnerabilities in Python
and PHP applications. A prototype of RESIN incurs a 33\% CPU
overhead running the HotCRP conference management application.

UMLSec \cite{ref_33_juerjens:secure} is a model-driven approach that allows the
development of secure applications with UML. Compared with
our approach, UMLSec does neither automatic code
generation nor the annotations can be used for automated
constraints checking.

TAJ \cite{ref_100_tripp2009taj}, an approach to taint analysis suitable for industrial applications. An experimental evaluation indicates that
the hybrid algorithm TAJ uses for slice construction is an attractive
compromise between context-sensitive and context-insensitive
thin slicing. TAJ is able to perform effective taint analysis in a limited budget, improving performance without significantly degrading accuracy.

Darvas, H{\"a}hnle, and Sands \cite{ref_70_darvas2005theorem} used a self-compositional approach to prove secure information flow properties for Java CARD programs. They used an interactive approach instead of an automatic approach. Barthe, D'Argenio, and Rezk coined the term "self-composition" in their paper \cite{ref_71_barthe2004secure}. Their paper is mostly theoretical results on characterizing various secure information flow problems, including
non-deterministic and termination-sensitive cases, in a self-compositional framework.

Wassermann and Su extended Minamide's string-analysis algorithm
\cite{ref_102_minamide2005static} to syntactically isolate tainted substrings from untainted
substrings in PHP applications. They labeled non-terminals in a
Context-Free Grammar (CFG) with annotations reflecting taintedness
and untaintedness. Their expensive, yet elegant mechanism
is applied to detect both SQL injection and XSS vulnerabilities.

McCamant and Ernst \cite{ref_101_mccamant2008quantitative} take a quantitative approach in information
flow: instead of using taint analysis, they cast information-
flow security to a network-flow-capacity problem, and describe a
dynamic technique for measuring the amount of secret data that
leaks to public observers.

Barthe, D'Argenio, and Rezk in the same paper showed that their self compositional framework can handle delimited information release as originally proposed by Sabelfeld and Myers \cite{ref_72_sabelfeld2004model}. Li and Zdancewic's
recently proposed relaxed non-interference \cite{ref_73_li2005downgrading} is equivalent to delimited information release when strengthened with semantic equivalence. Relaxed non-interference is arguably a more natural formulation of information downgrading than delimited
information release. This research suggests a promising practical approach of natural formulation of information downgrading.


The detection of information flow errors can be
addressed with dynamic analysis techniques \cite{ref_44_avgerinos:aeg,ref_43_fenton:memoryless,ref_42_sabelfeld:dynamic},
static analysis techniques \cite{ref_41_guarnieri:security,ref_40_myers:jflow,ref_39_simonet:report,ref_38_volpano:sound,ref_37_xiao:transparent} (similar
to our approach with respect to static analysis of code and
tracking of data information flow) and hybrid techniques which
combine static and dynamic approaches \cite{ref_36_moore:static}. Also, extended
static checking \cite{ref_35_david:extended} (ESC) is a promising research area which
tries to cope with the shortage of not having certain program
run-time information.
The static code analysis techniques need to know which
parts of the code are: sinks, sources and which variables
should be tagged. A solution for tagging these elements in
source code is based on a pre-annotated library which contains
all the needed annotations attached to function declarations.
Leino \cite{ref_34_leino:10years} reports about the annotation burden as being very
time consuming and disliked by some programming teams.

Security concerns are a major disincentive for use of the
cloud, particularly for companies responsible for sensitive
data. DIFC \cite{ref_74_bacon2014information} is most appropriately integrated into a PaaS cloud model which can be tested by augmenting
existing open source implementations such as VMware CloudFoundry
and Red Hat OpenShift. DIFC has been used to protect user
data integrity and secrecy. In order to apply these techniques
to a cloud environment a number of challenges need to be
overcome. These include: selecting the most appropriate DIFC
model; policy specification, translation, and enforcement; audit
logging to demonstrate compliance with legislation and for
digital forensics.

There exist several approaches that are focused on the detection of "taint-style" vulnerabilities (such as XSS or SQL injections), which
frequently occur in web applications. Huang et al. \cite{ref_75_huang2004securing}
adapted parts of the techniques used in CQual to develop
an intraprocedural analysis for PHP programs. In \cite{ref_76_huang2004verifying}, the
same authors presented an alternative approach that is based
on bounded model checking. Whaley and Lam \cite{ref_77_whaley2004cloning} described an interprocedural, flow-insensitive alias analysis for Java applications. Their analysis is based on binary decision diagrams and was used by Livshits and Lam \cite{ref_78_livshits2005finding} for the detection of taint-style vulnerabilities. In \cite{ref_62_balzarotti2008saner}, their approach is based on Pixy \cite{ref_79_jovanovic2010static,ref_80_jovanovic2006precise}, an open
source static PHP analyzer that uses taint analysis for detecting XSS vulnerabilities.

Weinberger et al. empirically studied present sanitization
approaches against XSS in web application frameworks \cite{ref_105_weinberger2011systematic}.
They analyzed the availability of sanitization approaches for
different HTML markup contexts for five PHP frameworks.
Furthermore, eight PHP applications were studied for the
usage of various markup contexts. A templating framework
was proposed by Samuel et al. that uses type qualifiers
to automate context-sensitive XSS sanitization \cite{ref_106_samuel2011context}.

A good overview of static analysis approaches applied to security problems are provided in  \cite{ref_81_chess2004static}. Simple lexical approaches employed by scanning tools such as ITS4 and RATS use a set of predefined patterns to identify potentially dangerous areas of a program \cite{ref_82_wilander2002comparison}. While a significant improvement on Unix grep, these tools, however, have no knowledge of how data propagates throughout the program and cannot be used to automatically and fully solve taint-style problems.
A few projects use path-sensitive analysis to find errors in C and C++ programs \cite{ref_83_bush2000static,ref_84_hallem2002system,ref_85_livshits2003tracking}. While capable of addressing taint-style problems, these tools rely on an unsound approach to pointers and may therefore miss some errors. The WebSSARI project uses combined unsound static and dynamic analysis in the context of analyzing PHP programs \cite{ref_75_huang2004securing}. WebSSARI has successfully been applied to find many SQL injection and cross-site scripting vulnerabilities in PHP code.

 The studies rely on manually
written annotations while our annotation language is integrated
into two editors which are be used to annotate UML state
charts and C code by selecting annotations from a list and
without the need to memorize a new annotation language.

Recently taint modes integrated in programming languages as Camlbased FlowCaml \cite{ref_32_simonet:report}, Ada-based SPARK Examiner \cite{ref_31_chapman:enforcing} and the scripting. However, none of these annotation and programming languages have support for introducing information flow
restrictions in both models and the source code.
Splint \cite{ref_30_david:splint}, Flawfinder \cite{ref_29_wheeler:flawfinder} and Cqual \cite{ref_28_umesh:cqual} are used to
detect information flow bugs in source code and come with
comprehensive user manuals describing how the annotation
language can be used in order to annotate source code.
iFlow \cite{ref_27_iflow:kuzman} is used for detecting information flow bugs in
models and is based on modeling dynamic behavior of the
application using UML sequence diagrams and translating
them into code by analyzing it with JOANA \cite{ref_26_kit:joana}. In comparison with our approach these tools do not use the same
annotation language for annotating UML models and code.
Thus, a user has to learn to use two annotation languages
which can be perceived to be a high burden in some scenarios.


 Heldal et al. \cite{ref_25_heldal:bridging,ref_23_heldal:supporting} introduced an
UML profile that incorporates a decentralized label model [40]
into the UML. It allows the annotation of UML artifacts with
Jif \cite{ref_24_myers:descentrelized} labels in order to generate Jif code from the UML
model automatically. However, the Jif-style annotation already
proved to be non-trivial on the code level \cite{ref_22_preibusch2011information}, while \cite{ref_23_heldal:supporting}
notes that the actual automatic Jif code generation is still a future
work. These approaches can not be used to annotate both UML
models and code. Moreover, these approaches lack of tools for
automated checking of previously imposed constraints.